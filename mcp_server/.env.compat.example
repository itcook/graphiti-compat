# Graphiti MCP OpenAI Compatible Version Environment Variables

# 大模型配置（分离）
LLM_BASE_URL=https://api.deepseek.com
LLM_API_KEY=sk-...
LLM_MODEL_NAME=deepseek-chat
LLM_SMALL_MODEL_NAME=  # 可选，为空或删除时回退到主模型
# 在本项目场景中，温度最好是低点，因为我们需要的是准确的回答，而不是需要 LLM 扩展发挥
LLM_TEMPERATURE=0.0

# Embedding 配置（分离）
# 如果使用本地模型，注意 docker 容器内访问 localhost 是指向容器自身的，需要使用 host.docker.internal 访问宿主机
EMBEDDING_BASE_URL=http://localhost:11434/v1
EMBEDDING_API_KEY=  # 本地模型可以为空或删除
EMBEDDING_MODEL_NAME=nomic-embed-text

# Neo4j 配置（保持不变）
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# 其他配置与原版保持一致
SEMAPHORE_LIMIT=10
